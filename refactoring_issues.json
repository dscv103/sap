{
  "generated_at": "2026-01-08T20:22:25.882663",
  "total_issues": 11,
  "branches": {
    "feature/backend-api": [
      {
        "title": "Refactor FIFO Engine: Extract Allocation Validation Logic",
        "body": "## Problem\nThe `fifoengine.py` currently mixes allocation calculation and validation logic, violating single responsibility principle. The `allocate_inventory()` method handles both preview and commit modes, making testing and maintenance difficult.\n\n## Proposed Solution\n1. Extract validation logic into separate `AllocationValidator` class\n2. Separate `AllocationCalculator` for pure FIFO calculations\n3. Keep `FIFOEngine` as orchestrator coordinating calculator and validator\n4. Implement clear interfaces using `typing.Protocol`\n\n## Benefits\n- Improved testability (can test validation independently)\n- Better separation of concerns\n- Easier to extend with new validation rules\n- Follows steering principles from `.kiro/steering/tech.md`\n\n## Acceptance Criteria\n- [ ] All existing FIFO allocation tests pass\n- [ ] New unit tests for `AllocationValidator` cover edge cases\n- [ ] Type hints use Protocol pattern per Python 3.13 standards\n- [ ] No behavioral changes to existing allocation logic\n\n## Related Requirements\nRequirements 4.1-4.7 (FIFO Allocation)\n\n## Priority\nP1 - High Impact on Code Quality\n",
        "labels": [
          "refactoring",
          "backend",
          "fifo-engine",
          "P1"
        ]
      },
      {
        "title": "Refactor Service Layer: Introduce Dependency Injection Container",
        "body": "## Problem\nServices (`dashboardservice.py`, `shipmentservice.py`, etc.) receive `DatabaseService` as parameters in every function call, leading to repetitive code and tight coupling. This pattern makes testing cumbersome and violates DRY principle.\n\n## Proposed Solution\n1. Create `ServiceContainer` class to manage service dependencies\n2. Initialize services with their dependencies at container level\n3. Use dataclass-based configuration for service setup\n4. Implement context manager pattern for resource lifecycle\n\n## Example\n```python\n@dataclass(frozen=True)\nclass ServiceContainer:\n    db_service: DatabaseService\n    lock_service: LockServiceProtocol\n    fifo_engine: FIFOEngine\n\n    @classmethod\n    def create(cls, db_path: Path) -> 'ServiceContainer':\n        db_service = DatabaseService(db_path)\n        lock_service = DBLockService(db_path.parent / '.lock')\n        fifo_engine = FIFOEngine(db_service)\n        return cls(db_service, lock_service, fifo_engine)\n```\n\n## Benefits\n- Reduces parameter passing boilerplate\n- Centralized dependency management\n- Easier to mock for testing\n- Follows steering architecture patterns\n\n## Acceptance Criteria\n- [ ] All service modules refactored to use container\n- [ ] Existing functionality unchanged\n- [ ] Test fixtures updated to use container\n- [ ] Type hints complete with `Protocol` interfaces\n\n## Related Requirements\nAll service-layer requirements (5.x, 6.x, 7.x, 8.x)\n\n## Priority\nP1 - Architectural Improvement\n",
        "labels": [
          "refactoring",
          "backend",
          "architecture",
          "services",
          "P1"
        ]
      },
      {
        "title": "Refactor Concurrency: Replace File-Based Lock with Database-Level Locking",
        "body": "## Problem\nCurrent file-based locking (`dblock.py`) has limitations:\n- Stale lock detection is heuristic-based (5-minute threshold)\n- Lock file management adds I/O overhead\n- Race conditions possible in lock cleanup\n- Network filesystem can cause false stale locks\n\n## Proposed Solution\n1. Implement advisory locking using SQLite's `BEGIN IMMEDIATE` transactions\n2. Add `LockMode` enum: `IMMEDIATE`, `EXCLUSIVE`, `DEFERRED`\n3. Create `DatabaseLockService` implementing `LockServiceProtocol`\n4. Keep file-based lock as fallback for compatibility\n\n## Benefits\n- Database-native concurrency control\n- Automatic cleanup on connection close\n- Better performance (no separate lock file I/O)\n- Eliminates stale lock false positives\n\n## Migration Strategy\n1. Implement new `DatabaseLockService` alongside existing\n2. Add feature flag to switch between implementations\n3. Test thoroughly in multi-user scenarios\n4. Deprecate file-based lock after validation period\n\n## Acceptance Criteria\n- [ ] `DatabaseLockService` implements `LockServiceProtocol`\n- [ ] All concurrency tests pass with new implementation\n- [ ] Feature flag enables AB testing\n- [ ] Performance benchmarks show improvement\n- [ ] Documentation updated with migration guide\n\n## Related Requirements\nRequirements 3.1-3.7 (Concurrency Control)\n\n## Priority\nP2 - Performance Optimization (non-blocking)\n",
        "labels": [
          "refactoring",
          "backend",
          "concurrency",
          "performance",
          "P2"
        ]
      }
    ],
    "feature/database-schema": [
      {
        "title": "Refactor Database Schema: Add Domain Event Tables",
        "body": "## Problem\nCurrent schema only tracks current state (`assetsin.qtyremaining`) without preserving complete event history. Audit trail reconstruction requires parsing `expensesout.batchidsused` CSV field, which is brittle and violates normalization.\n\n## Proposed Solution\n1. Create `inventory_events` table for event sourcing pattern:\n   - `event_id`, `event_type`, `batch_id`, `quantity`, `timestamp`, `user_id`\n2. Create `batch_transactions` junction table normalizing batch-expense relationship\n3. Keep existing tables for backward compatibility\n4. Add database views for common queries\n\n## Schema Design\n```sql\nCREATE TABLE inventory_events (\n    event_id INTEGER PRIMARY KEY,\n    event_type VARCHAR(20) NOT NULL,  -- 'RECEIVED', 'ISSUED', 'ADJUSTED'\n    batch_id INTEGER NOT NULL,\n    quantity_delta INTEGER NOT NULL,\n    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n    user_id VARCHAR(50),\n    FOREIGN KEY (batch_id) REFERENCES assetsin(batchid)\n);\n\nCREATE TABLE batch_transactions (\n    id INTEGER PRIMARY KEY,\n    transaction_id INTEGER NOT NULL,\n    batch_id INTEGER NOT NULL,\n    quantity_allocated INTEGER NOT NULL,\n    cost_allocated NUMERIC(12,2) NOT NULL,\n    FOREIGN KEY (transaction_id) REFERENCES expensesout(transactionid),\n    FOREIGN KEY (batch_id) REFERENCES assetsin(batchid)\n);\n```\n\n## Benefits\n- True event sourcing for complete audit trail\n- Normalized relationships (no CSV parsing)\n- Enables point-in-time inventory reconstruction\n- Better query performance for audit reports\n\n## Migration Strategy\n1. Add new tables without touching existing schema\n2. Dual-write to both old and new tables during transition\n3. Backfill historical events from existing data\n4. Validate data consistency\n5. Eventually deprecate `batchidsused` CSV field\n\n## Acceptance Criteria\n- [ ] Migration script creates new tables\n- [ ] Backward compatibility maintained\n- [ ] All audit queries work with new schema\n- [ ] Performance tests show no degradation\n- [ ] Requirements 9.x still satisfied\n\n## Related Requirements\nRequirements 9.1-9.7 (Data Integrity & Audit Trail)\n\n## Priority\nP2 - Data Model Enhancement\n",
        "labels": [
          "refactoring",
          "database",
          "schema",
          "audit-trail",
          "P2"
        ]
      },
      {
        "title": "Refactor Database Access: Implement Repository Pattern",
        "body": "## Problem\nDirect SQLAlchemy queries scattered across service modules violate separation of concerns. Changes to database schema require updates in multiple locations. No clear abstraction boundary between business logic and data access.\n\n## Proposed Solution\n1. Create repository interfaces using `typing.Protocol`:\n   - `InventoryRepository`: batch CRUD operations\n   - `TransactionRepository`: expense tracking\n   - `ReportingRepository`: reconciliation queries\n2. Implement SQLAlchemy-based repositories\n3. Inject repositories into services via container\n\n## Example\n```python\nclass InventoryRepositoryProtocol(Protocol):\n    def get_available_batches(self, description: str) -> list[Batch]: ...\n    def update_batch_quantity(self, batch_id: int, new_qty: int) -> None: ...\n    def create_batch(self, batch_data: BatchCreate) -> int: ...\n\nclass SQLAlchemyInventoryRepository:\n    def __init__(self, session_factory: sessionmaker) -> None:\n        self._session_factory = session_factory\n\n    def get_available_batches(self, description: str) -> list[Batch]:\n        with self._session_factory() as session:\n            return session.query(AssetsIn)\\\n                .filter(AssetsIn.description == description)\\\n                .filter(AssetsIn.qtyremaining > 0)\\\n                .order_by(AssetsIn.datereceived.asc())\\\n                .all()\n```\n\n## Benefits\n- Single source of truth for data access logic\n- Easier to mock for unit testing\n- Database schema changes isolated to repositories\n- Enables future database migration (SQLite \u2192 PostgreSQL)\n- Follows steering architecture principles\n\n## Acceptance Criteria\n- [ ] Repository protocols defined with full type hints\n- [ ] All existing queries migrated to repositories\n- [ ] Service layer no longer imports SQLAlchemy models directly\n- [ ] Test coverage maintained or improved\n- [ ] No breaking changes to public service APIs\n\n## Related Requirements\nAll data-layer interactions (Requirements 2.x, 9.x, 10.x)\n\n## Priority\nP1 - Architectural Foundation\n",
        "labels": [
          "refactoring",
          "database",
          "architecture",
          "repository-pattern",
          "P1"
        ]
      }
    ],
    "feature/frontend-ui": [
      {
        "title": "Refactor Streamlit Pages: Extract Reusable UI Components",
        "body": "## Problem\nStreamlit page files (`1_Dashboard.py`, `2_LogShipment.py`, etc.) contain duplicated UI patterns:\n- Form validation and error display logic repeated\n- Session state management boilerplate\n- Lock acquisition/release patterns duplicated\n- Success/error message formatting inconsistent\n\n## Proposed Solution\n1. Create `components/` directory for reusable UI components:\n   - `form_components.py`: validated input fields\n   - `message_components.py`: standardized alerts\n   - `lock_components.py`: lock acquisition context managers\n   - `layout_components.py`: common layouts (headers, footers)\n2. Use Streamlit's `@st.cache_resource` for component factories\n3. Implement composable component pattern\n\n## Example Components\n```python\n# components/form_components.py\ndef validated_number_input(\n    label: str,\n    min_value: int = 0,\n    key: str | None = None,\n    validation_fn: Callable[[int], str | None] | None = None\n) -> int | None:\n    \"\"\"Validated numeric input with inline error display.\"\"\"\n    value = st.number_input(label, min_value=min_value, key=key)\n    if validation_fn and (error := validation_fn(value)):\n        st.error(error)\n        return None\n    return value\n\n# components/message_components.py\ndef show_operation_result(\n    success: bool,\n    success_msg: str,\n    error_msg: str | None = None,\n    duration: int = 3\n) -> None:\n    \"\"\"Standardized success/error messaging.\"\"\"\n    if success:\n        st.success(success_msg)\n        time.sleep(duration)\n    elif error_msg:\n        st.error(error_msg)\n```\n\n## Benefits\n- DRY principle applied to UI code\n- Consistent user experience across pages\n- Easier to update UI patterns globally\n- Better testability of UI logic\n- Follows steering structure patterns\n\n## Acceptance Criteria\n- [ ] `components/` module created with organized sub-modules\n- [ ] All pages refactored to use common components\n- [ ] No UI behavior changes\n- [ ] Component documentation with usage examples\n- [ ] Requirements 11.x still satisfied (UI/Error Handling)\n\n## Related Requirements\nRequirements 11.1-11.7 (UI & Error Handling)\n\n## Priority\nP1 - Code Quality & Maintainability\n",
        "labels": [
          "refactoring",
          "frontend",
          "ui-components",
          "P1"
        ]
      },
      {
        "title": "Refactor Session State: Implement Type-Safe State Management",
        "body": "## Problem\nStreamlit session state accessed via string keys (`st.session_state['key']`) leads to:\n- Runtime errors from typos\n- No IDE autocomplete\n- Unclear state schema\n- Difficult to track state dependencies\n\n## Proposed Solution\n1. Create typed state dataclasses for each page:\n   - `DashboardState`, `ShipmentFormState`, `RequestCardState`\n2. Implement state manager with property accessors\n3. Use `st.session_state` as backing store with type safety layer\n\n## Example\n```python\n# state/models.py\nfrom dataclasses import dataclass, field\nfrom typing import Optional\nfrom decimal import Decimal\n\n@dataclass\nclass RequestCardState:\n    card_description: str = \"\"\n    qty_requested: int = 0\n    project_code: str = \"\"\n    gl_account: str = \"\"\n    preview_result: Optional[AllocationResult] = None\n    operation_in_progress: bool = False\n\n    @property\n    def is_valid(self) -> bool:\n        return (\n            bool(self.card_description) and\n            self.qty_requested > 0 and\n            bool(self.project_code)\n        )\n\n# state/manager.py\nclass SessionStateManager:\n    def __init__(self, state_key: str, state_cls: type):\n        self._key = state_key\n        self._cls = state_cls\n\n    def get(self) -> Any:\n        if self._key not in st.session_state:\n            st.session_state[self._key] = self._cls()\n        return st.session_state[self._key]\n\n    def update(self, **kwargs) -> None:\n        state = self.get()\n        for key, value in kwargs.items():\n            if hasattr(state, key):\n                setattr(state, key, value)\n\n    def reset(self) -> None:\n        st.session_state[self._key] = self._cls()\n\n# Usage in page\nstate_mgr = SessionStateManager('request_card', RequestCardState)\nstate = state_mgr.get()\n\nif state.is_valid:\n    st.button(\"Submit\", disabled=state.operation_in_progress)\n```\n\n## Benefits\n- Type safety with IDE autocomplete\n- Clear state schema documentation\n- Validation logic encapsulated in state classes\n- Easier state debugging and logging\n- Follows Python 3.13 type hint standards\n\n## Acceptance Criteria\n- [ ] State dataclasses defined for all pages\n- [ ] `SessionStateManager` implemented with full type hints\n- [ ] All pages migrated to typed state management\n- [ ] No functional behavior changes\n- [ ] mypy type checking passes\n\n## Related Requirements\nAll UI requirements with session state (5.x, 6.x, 7.x, 8.x)\n\n## Priority\nP2 - Developer Experience Enhancement\n",
        "labels": [
          "refactoring",
          "frontend",
          "state-management",
          "type-safety",
          "P2"
        ]
      }
    ],
    "tooling/testing": [
      {
        "title": "Refactor Test Suite: Implement Property-Based Testing for FIFO Allocation",
        "body": "## Problem\nCurrent unit tests use fixed examples and may miss edge cases in FIFO allocation logic. Complex scenarios (multi-batch, partial allocation, race conditions) are difficult to enumerate manually.\n\n## Proposed Solution\n1. Introduce Hypothesis for property-based testing\n2. Define FIFO allocation invariants as properties:\n   - Total allocated cost always equals sum of batch costs\n   - Allocation always uses oldest batches first\n   - Partial allocations don't skip batches\n   - Remaining inventory correctness\n3. Generate random batch configurations and requests\n4. Verify properties hold across all generated cases\n\n## Example Properties\n```python\nfrom hypothesis import given, strategies as st\nfrom decimal import Decimal\n\n@given(\n    batches=st.lists(\n        st.fixed_dictionaries({\n            'qty': st.integers(min_value=1, max_value=1000),\n            'unit_cost': st.decimals(min_value='0.01', max_value='10.00', places=4),\n            'date_received': st.datetimes()\n        }),\n        min_size=1,\n        max_size=10\n    ),\n    qty_requested=st.integers(min_value=1, max_value=5000)\n)\ndef test_fifo_allocation_properties(batches, qty_requested):\n    # Property 1: Oldest batches used first\n    allocation = allocate_inventory(batches, qty_requested)\n    if allocation.success:\n        used_dates = [b['date_received'] for b in allocation.batches_used]\n        assert used_dates == sorted(used_dates)\n\n    # Property 2: Cost calculation correctness\n    if allocation.success:\n        manual_cost = sum(\n            Decimal(b['qty_allocated']) * b['unit_cost']\n            for b in allocation.batches_used\n        )\n        assert allocation.total_cost == manual_cost\n\n    # Property 3: No batch skipping in partial allocation\n    if not allocation.success:\n        total_available = sum(b['qty'] for b in batches)\n        assert total_available < qty_requested\n```\n\n## Benefits\n- Discovers edge cases automatically\n- Validates FIFO invariants comprehensively\n- Builds confidence in allocation correctness\n- Self-documenting test properties\n- Catches regression bugs early\n\n## Acceptance Criteria\n- [ ] Hypothesis added to test dependencies\n- [ ] Property tests cover FIFO allocation engine\n- [ ] At least 5 meaningful properties tested\n- [ ] Tests run in CI pipeline\n- [ ] Documentation explains property-based testing approach\n\n## Related Requirements\nRequirements 4.1-4.7 (FIFO Allocation)\n\n## Priority\nP2 - Test Coverage Enhancement\n",
        "labels": [
          "refactoring",
          "testing",
          "fifo-engine",
          "property-testing",
          "P2"
        ]
      },
      {
        "title": "Refactor Test Fixtures: Implement Factory Pattern for Test Data",
        "body": "## Problem\nTest fixtures create data using repetitive boilerplate code. Changes to data models require updating multiple test files. No centralized factory for creating consistent test data with sensible defaults.\n\n## Proposed Solution\n1. Create `tests/factories.py` with factory functions using `dataclasses`\n2. Implement `FactoryBuilder` pattern for fluent test data construction\n3. Use factory fixtures in pytest for reusable test setups\n\n## Example Factory\n```python\n# tests/factories.py\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone\nfrom decimal import Decimal\nfrom typing import Optional\n\n@dataclass\nclass BatchFactory:\n    batch_id: int = field(default_factory=lambda: BatchFactory._next_id())\n    date_received: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n    vendor: str = \"Test Vendor\"\n    description: str = \"Visa Debit\"\n    qty_original: int = 100\n    qty_remaining: int = 100\n    unit_cost: Decimal = Decimal(\"1.2345\")\n    invoice_number: str = field(default_factory=lambda: f\"INV-{BatchFactory._next_id()}\")\n\n    _id_counter: int = 0\n\n    @classmethod\n    def _next_id(cls) -> int:\n        cls._id_counter += 1\n        return cls._id_counter\n\n    @classmethod\n    def create(cls, **overrides) -> 'AssetsIn':\n        \"\"\"Create batch with optional field overrides.\"\"\"\n        factory = cls(**overrides)\n        return AssetsIn(\n            batchid=factory.batch_id,\n            datereceived=factory.date_received,\n            vendor=factory.vendor,\n            description=factory.description,\n            qtyoriginal=factory.qty_original,\n            qtyremaining=factory.qty_remaining,\n            unitcost=factory.unit_cost,\n            invoicenumber=factory.invoice_number\n        )\n\n    @classmethod\n    def create_batch(cls, **overrides):\n        \"\"\"Fluent builder for multiple batches.\"\"\"\n        return cls.create(**overrides)\n\n# Usage in tests\ndef test_fifo_allocation_multiple_batches():\n    batch1 = BatchFactory.create(qty_remaining=50, unit_cost=Decimal(\"1.00\"))\n    batch2 = BatchFactory.create(qty_remaining=100, unit_cost=Decimal(\"1.50\"))\n\n    result = fifo_engine.allocate_inventory(\"Visa Debit\", 75)\n\n    assert len(result.allocations) == 2\n    assert result.allocations[0].batch_id == batch1.batchid\n```\n\n## Benefits\n- DRY test data creation\n- Sensible defaults reduce test verbosity\n- Easy to override specific fields\n- Centralized management of test data patterns\n- Easier to maintain when models change\n\n## Acceptance Criteria\n- [ ] Factory classes created for all major entities\n- [ ] Existing tests refactored to use factories\n- [ ] Factory documentation with usage examples\n- [ ] Factories support fluent builder pattern\n- [ ] Test execution time not significantly increased\n\n## Related Requirements\nAll requirements (test data needed across all features)\n\n## Priority\nP2 - Test Maintainability\n",
        "labels": [
          "refactoring",
          "testing",
          "test-fixtures",
          "factories",
          "P2"
        ]
      }
    ],
    "feature/error-handling": [
      {
        "title": "Refactor Error Handling: Implement Structured Exception Hierarchy",
        "body": "## Problem\nCurrent exception handling uses generic `Exception` and string messages, making it difficult to:\n- Handle specific error cases programmatically\n- Provide appropriate user feedback\n- Log errors with structured context\n- Distinguish between client vs server errors\n\n## Proposed Solution\n1. Create domain-specific exception hierarchy:\n   ```\n   CardInventoryError (base)\n   \u251c\u2500\u2500 ValidationError (4xx equivalents)\n   \u2502   \u251c\u2500\u2500 InsufficientInventoryError\n   \u2502   \u251c\u2500\u2500 DuplicateInvoiceError\n   \u2502   \u2514\u2500\u2500 InvalidInputError\n   \u251c\u2500\u2500 ConcurrencyError (409 equivalents)\n   \u2502   \u251c\u2500\u2500 LockTimeoutError\n   \u2502   \u251c\u2500\u2500 AllocationRaceConditionError\n   \u2502   \u2514\u2500\u2500 StaleLockError\n   \u2514\u2500\u2500 SystemError (5xx equivalents)\n       \u251c\u2500\u2500 DatabaseConnectionError\n       \u251c\u2500\u2500 NetworkShareError\n       \u2514\u2500\u2500 ConfigurationError\n   ```\n\n2. Add structured error context using dataclasses\n3. Implement error serialization for logging\n4. Create error-to-UI-message mapping\n\n## Example Implementation\n```python\n# errors/base.py\nfrom dataclasses import dataclass, field\nfrom typing import Optional, Any\nfrom datetime import datetime, timezone\n\n@dataclass(frozen=True)\nclass ErrorContext:\n    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n    user_id: Optional[str] = None\n    operation: Optional[str] = None\n    details: dict[str, Any] = field(default_factory=dict)\n\nclass CardInventoryError(Exception):\n    \"\"\"Base exception for card inventory system.\"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        context: Optional[ErrorContext] = None,\n        cause: Optional[Exception] = None\n    ) -> None:\n        super().__init__(message)\n        self.message = message\n        self.context = context or ErrorContext()\n        self.__cause__ = cause\n\n    def to_user_message(self) -> str:\n        \"\"\"Convert to user-friendly message.\"\"\"\n        return self.message\n\n    def to_log_dict(self) -> dict[str, Any]:\n        \"\"\"Structured logging format.\"\"\"\n        return {\n            'error_type': self.__class__.__name__,\n            'message': self.message,\n            'timestamp': self.context.timestamp.isoformat(),\n            'user_id': self.context.user_id,\n            'operation': self.context.operation,\n            'details': self.context.details\n        }\n\n# errors/validation.py\nclass InsufficientInventoryError(CardInventoryError):\n    def __init__(\n        self,\n        requested: int,\n        available: int,\n        card_description: str\n    ) -> None:\n        context = ErrorContext(\n            operation='allocate_inventory',\n            details={\n                'requested_qty': requested,\n                'available_qty': available,\n                'card_description': card_description\n            }\n        )\n        super().__init__(\n            f\"Insufficient inventory: requested {requested}, only {available} available\",\n            context=context\n        )\n        self.requested = requested\n        self.available = available\n        self.card_description = card_description\n\n    def to_user_message(self) -> str:\n        return f\"Only {self.available} {self.card_description} cards available. Please adjust quantity.\"\n\n# Usage in service\ntry:\n    result = fifo_engine.allocate_inventory(card_type, qty)\nexcept InsufficientInventoryError as e:\n    logger.warning(\"Insufficient inventory\", extra=e.to_log_dict())\n    st.error(e.to_user_message())\nexcept CardInventoryError as e:\n    logger.error(\"Operation failed\", extra=e.to_log_dict())\n    st.error(\"An unexpected error occurred. Please try again.\")\n```\n\n## Benefits\n- Type-safe error handling\n- Structured logging with full context\n- Consistent user messaging\n- Easier to add error telemetry/monitoring\n- Follows Python 3.13 exception best practices\n- Aligns with steering error-handling patterns\n\n## Acceptance Criteria\n- [ ] Exception hierarchy implemented with full type hints\n- [ ] All service/engine code uses custom exceptions\n- [ ] UI pages use `to_user_message()` for display\n- [ ] Logging uses `to_log_dict()` for structured output\n- [ ] All existing error cases covered\n- [ ] Requirements 11.3 satisfied (no SQL/stack traces exposed)\n\n## Related Requirements\nRequirements 11.1-11.3 (Error Handling & Display)\n\n## Priority\nP1 - Error Handling Foundation\n",
        "labels": [
          "refactoring",
          "error-handling",
          "exceptions",
          "logging",
          "P1"
        ]
      }
    ],
    "docs/technical-debt": [
      {
        "title": "Technical Debt: Document Known Limitations and Workarounds",
        "body": "## Problem\nSeveral architectural decisions were made as pragmatic compromises for the MVP:\n- File-based locking instead of database transactions\n- CSV field `batchidsused` instead of normalized junction table\n- No retry logic for network filesystem disconnections\n- Streamlit's auto-reload can cause lock state inconsistencies\n\nThese limitations are scattered across code comments and not centrally documented.\n\n## Proposed Solution\nCreate `docs/TECHNICAL_DEBT.md` documenting:\n1. Each known limitation with rationale\n2. Impact assessment (severity, frequency)\n3. Recommended resolution approach\n4. Estimated effort to resolve\n5. Priority ranking based on user impact\n\n## Template Structure\n```markdown\n# Technical Debt Inventory\n\n## TD-001: File-Based Locking Limitations\n**Category**: Concurrency Control\n**Severity**: Medium\n**Frequency**: Rare (< 1% of operations)\n\n### Description\nCurrent file-based locking uses 5-minute stale threshold which can cause false positives on slow networks.\n\n### Impact\n- Users occasionally see \"System Busy\" when lock is actually stale\n- Manual intervention required to delete .lock file in extreme cases\n\n### Workaround\nUsers can wait for 5-minute timeout or contact admin to remove .lock file.\n\n### Proposed Resolution\nMigrate to SQLite advisory locking with `BEGIN IMMEDIATE` transactions.\n\n### Effort Estimate\n- Implementation: 8 hours\n- Testing: 4 hours  \n- Migration: 2 hours\n\n### Priority\nP2 - Address after core features stable\n\n### Related Issues\n- #XXX (Refactor Concurrency: Database-Level Locking)\n\n### References\n- research.md: Stale Lock Timeout decision\n- Requirement 3.6\n```\n\n## Benefits\n- Transparent communication of system limitations\n- Prioritized roadmap for debt resolution\n- Helps new developers understand design trade-offs\n- Informs users of known issues and workarounds\n- Tracks debt reduction progress over time\n\n## Deliverables\n1. `docs/TECHNICAL_DEBT.md` with all identified debt items\n2. GitHub issues created for high-priority debt\n3. Debt items linked in code comments where relevant\n4. Regular review cadence established (quarterly)\n\n## Acceptance Criteria\n- [ ] All known limitations documented\n- [ ] Each item has severity, impact, resolution plan\n- [ ] Document linked from main README\n- [ ] Process for tracking new debt established\n\n## Priority\nP2 - Documentation & Transparency\n",
        "labels": [
          "documentation",
          "technical-debt",
          "process",
          "P2"
        ]
      }
    ]
  }
}